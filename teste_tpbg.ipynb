{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7095\n",
      "6175\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from pbg import PBG\n",
    "from util import Loader\n",
    "from sklearn.pipeline import Pipeline\n",
    "from preprocessor import Preprocessor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "\n",
    "# carrega matrix\n",
    "s_dataset = '/exp/datasets/docs_rotulados/classic3'\n",
    "l = Loader()\n",
    "d = l.from_files(s_dataset)\n",
    "\n",
    "print(len(d['corpus']))\n",
    "# Préprocessamento\n",
    "for i,s in enumerate(d['corpus']):\n",
    "    if len(s.split()) < 10:\n",
    "        del d['class_index'][i]\n",
    "        del d['corpus'][i]\n",
    "print(len(d['corpus']))\n",
    "\n",
    "cvect = CountVectorizer()\n",
    "steps = [('preprocessor',Preprocessor()), ('countvectorizer',cvect)]\n",
    "pipe = Pipeline(steps) \n",
    "pipe.fit(d['corpus'])\n",
    "M = pipe.transform(d['corpus'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.5, 0.5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def init_vectors(M,y,k, unlabelled_idx=-1, beta=0.0):\n",
    "    ndocs,nwords = M.shape\n",
    "    B = np.full((nwords,k),beta)\n",
    "    count={}\n",
    "    for word in range(nwords): count[word] = defaultdict(int)\n",
    "    rows,cols = M.nonzero()\n",
    "    for row,col in zip(rows,cols):\n",
    "        label = y[row]\n",
    "        if label != unlabelled_idx:\n",
    "            count[col][label] += M[row,col]\n",
    "            count[col][-1] += M[row,col]\n",
    "    for word in range(nwords):\n",
    "        for cls in count[word]:\n",
    "            if cls != -1: B[word][cls] = (beta + count[word][cls])/(beta + count[word][-1])\n",
    "    return B\n",
    "\n",
    "M2 = np.array([[1,2,4,0,4],[1,2,0,10,4],[2,4,0,2,4]])\n",
    "y2 = np.array([0,1,-1])\n",
    "\n",
    "init_vectors(M2,y2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<util.ConfigLabels at 0x7fd124209240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import ConfigLabels\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# escolhes quantos dados rotulados\n",
    "number_labelled_examples = [10,20,30,40,50,100] # 10,20,..,50 exemplos rotulados por classe\n",
    "conf_labels = ConfigLabels(list_n_labels=number_labelled_examples)\n",
    "conf_labels.fit(d['class_index']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PBG(alpha=0.05, beta=0.001, calc_q=False, debug=False, global_max_itr=10,\n",
       "  global_threshold=1e-06, local_max_itr=10, local_threshold=1e-06,\n",
       "  max_time=18000, n_components=4, out_A='A', out_B='B', out_dir='.',\n",
       "  rand_init=False, save_interval=-1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pbg import PBG\n",
    "from util import RandMatrices\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# teste com 50 dados rotulados\n",
    "n_examples_labelled = 10\n",
    "#vetor y com os rótulos, apenas 50 exemplos rotulados\n",
    "y = conf_labels.semi_labels[n_examples_labelled]\n",
    "# numero de classes\n",
    "K = len(np.unique(d['class_index'])) \n",
    "\n",
    "pbg = PBG(K, alpha=0.05, beta=0.001, local_max_itr=10, \n",
    "              global_max_itr=10, local_threshold = 1e-6, global_threshold = 1e-6, \n",
    "              max_time=18000, save_interval=-1, out_dir='.', out_A='A', out_B='B', calc_q=False, debug=False)\n",
    "# executa pbg transdutivo\n",
    "\n",
    "pbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PBG(alpha=0.05, beta=0.001, calc_q=False, debug=False, global_max_itr=10,\n",
       "  global_threshold=1e-06, local_max_itr=10, local_threshold=1e-06,\n",
       "  max_time=18000, n_components=4, out_A='A', out_B='B', out_dir='.',\n",
       "  rand_init=False, save_interval=-1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbg.fit(M, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      1388\n",
      "          1       0.84      0.94      0.89      1450\n",
      "          2       0.95      0.87      0.91      2274\n",
      "          3       1.00      0.97      0.99      1023\n",
      "\n",
      "avg / total       0.93      0.93      0.93      6135\n",
      "\n",
      "Confusion matrix\n",
      "[[1372    6   10    0]\n",
      " [   2 1361   86    1]\n",
      " [  64  235 1973    2]\n",
      " [   4   21    2  996]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_unlabelled = conf_labels.unlabelled_idx[n_examples_labelled]\n",
    "predicted_labels = pbg.transduction_[y_unlabelled]\n",
    "true_labels = np.array(d['class_index'])[y_unlabelled]\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=pbg.classes_)\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABAIXO ESTÁ EXEMPLO COM O LABEL PROPAGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiagodepaulo/anaconda3/lib/python3.6/site-packages/sklearn/semi_supervised/label_propagation.py:288: ConvergenceWarning: max_iter=30 was reached without convergence.\n",
      "  category=ConvergenceWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.8, gamma=20, kernel='knn', max_iter=30, n_jobs=1,\n",
       "        n_neighbors=7, tol=0.001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.semi_supervised import label_propagation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.sparse import csgraph\n",
    "\n",
    "# Learn with LabelSpreading\n",
    "label_spread = label_propagation.LabelSpreading(kernel='knn', alpha=0.8)\n",
    "label_spread.fit(M.toarray(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.25      0.36        57\n",
      "          1       0.10      0.93      0.18        14\n",
      "          2       1.00      0.20      0.33         5\n",
      "          3       0.73      0.12      0.21        90\n",
      "\n",
      "avg / total       0.67      0.23      0.26       166\n",
      "\n",
      "Confusion matrix\n",
      "[[14 39  0  4]\n",
      " [ 1 13  0  0]\n",
      " [ 0  4  1  0]\n",
      " [ 6 73  0 11]]\n"
     ]
    }
   ],
   "source": [
    "y_unlabelled = conf_labels.unlabelled_idx[n_examples_labelled]\n",
    "predicted_labels = label_spread.transduction_[y_unlabelled]\n",
    "true_labels = np.array(d['class_index'])[y_unlabelled]\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=label_spread.classes_)\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
